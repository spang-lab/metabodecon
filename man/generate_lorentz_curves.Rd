% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/30_generate_lorentz_curves.R
\name{generate_lorentz_curves}
\alias{generate_lorentz_curves}
\title{Generate Lorentz Curves from NMR Spectra}
\usage{
generate_lorentz_curves(
  data_path = system.file("example_datasets/bruker/urine/urine_1", package =
    "metabodecon"),
  file_format = "bruker",
  make_rds = FALSE,
  expno = 10,
  procno = 10,
  nfit = 10,
  wshw = 0.1527692,
  sfr = c(11.44494, -1.8828),
  smopts = c(2, 5),
  delta = 6.4,
  sf = c(1000, 1e+06),
  ask = TRUE,
  debug = FALSE,
  nworkers = "auto",
  share_stdout = FALSE,
  force = FALSE,
  verbose = TRUE
)
}
\arguments{
\item{data_path}{Either the path to a directory containing measured NMR spectra, a dataframe as returned by \code{\link[=read_spectrum]{read_spectrum()}}, or a list of such dataframes.}

\item{file_format}{Format of the spectra files. Either \code{"bruker"} or \code{"jcampdx"}. Only relevant if \code{data_path} is a directory.}

\item{make_rds}{Logical or character. If TRUE, stores results as an RDS file on disk. If a character string, saves the RDS file with the specified name. Should be set to TRUE if many spectra are evaluated to decrease computation time.}

\item{expno}{The experiment number for the spectra files, e.g., \code{"10"}. Only relevant if \code{data_path} is a directory and \code{file_format} is \code{"bruker"}.}

\item{procno}{The processing number for the spectra, e.g., \code{"10"}. Only relevant if \code{data_path} is a directory and \code{file_format} is \code{"bruker"}.}

\item{nfit}{Number of iterations for approximating the parameters for the Lorentz curves.}

\item{wshw}{Half-width of the water artifact in ppm.}

\item{sfr}{Numeric vector with two entries: the ppm positions for the left and right border of the signal-free region of the spectrum.}

\item{smopts}{Numeric vector with two entries: the number of smoothing iterations and the number of data points to use for smoothing (must be odd).}

\item{delta}{Threshold value to distinguish between signal and noise.}

\item{sf}{Numeric vector with two entries: the factors to scale the x-axis and y-axis.}

\item{ask}{Logical. Whether to ask for user input during the deconvolution process. If FALSE, the provided default values will be used.}

\item{debug}{Logical. Whether to return additional intermediate results for debugging purposes.}

\item{nworkers}{Number of workers to use for parallel processing. If \code{"auto"}, the number of workers will be determined automatically. If a number greater than 1, it will be limited to the number of spectra.}

\item{share_stdout}{Whether to share the standard output (usually your terminal) of the main process with the worker processes. Only relevant if \code{nworkers} is greater than 1. Note that this can cause messages from different processes to get mixed up, making the output hard to follow.}

\item{force}{If FALSE, the function stops with an error message if no peaks are found in the SFR (which are used as reference for peak filtering). If TRUE, the function instead proceeds without peak filtering, potentially increasing runtime and memory usage significantly.}

\item{verbose}{Logical. Whether to print log messages during the deconvolution process.}
}
\value{
A list of deconvoluted spectra. Each list element contains a list with the following elements:
\itemize{
\item \code{number_of_files}: Number of deconvoluted spectra.
\item \code{filename}: Name of the analyzed spectrum.
\item \code{x_values}: Scaled datapoint numbers (SDP). Datapoints are numbered in descending order going from N to 0, where N equals the . Scaled data point numbers are obtained by dividing these numbers by the x-axis scale factor \code{sf[1]}. I.e., for a spectrum with 131072 datapoints and a scale factor of 1000, the first scale datapoint has value 131.071 and the last one has value 0.
\item \code{x_values_ppm}: The chemical shift of each datapoint in ppm (parts per million).
\item \code{y_values}: The scaled signal intensity (SSI) of each datapoint. Obtained by reading the raw intensity values from the provided \code{data_path} as integers and dividing them by the y-axis scale factor \code{sf[2]}.
\item \code{spectrum_superposition}: Scaled signal intensity obtained by calculating the sum of all estimated Lorentz curves for each data point.
\item \code{mse_normed}: Normalized mean squared error. Calculated as \eqn{\frac{1}{n} \sum_{i=1}^{n} (z_i - \hat{z}_i)^2} where \eqn{z_i} is the normalized, smoothed signal intensity of data point i and \eqn{\hat{z}_i} is the normalized superposition of Lorentz curves at data point i. Normalized in this context means that the vectors were scaled so the sum over all data points equals 1.
\item \code{index_peak_triplets_middle}: Datapoint numbers of peak centers.
\item \code{index_peak_triplets_left}: Datapoint numbers of left peak borders.
\item \code{index_peak_triplets_right}: Datapoint numbers of right peak borders.
\item \code{peak_triplets_middle}: Chemical shift of peak centers in ppm .
\item \code{peak_triplets_left}: Chemical shift of left peak borders in ppm .
\item \code{peak_triplets_right}: Chemical shift of right peak borders in ppm .
\item \code{integrals}: Integrals of the Lorentz curves.
\item \code{signal_free_region}: Borders of the signal free region of the spectrum in scaled datapoint numbers. Left of the first element and right of the second element no signals are expected.
\item \code{range_water_signal_ppm}: Half width of the water signal in ppm. Potential signals in this region are ignored.
\item \code{A}: Amplitude parameter of the Lorentz curves. Provided as negative number to maintain backwards compatibility with MetaboDecon1D. The area under the Lorentz curve is calculated as \eqn{A \cdot \pi}.
\item \code{lambda}: Half width of the Lorentz curves in scaled data points. Provided as negative value to maintain backwards compatibility with MetaboDecon1D. Example: a value of -0.00525 corresponds to 5.25 data points. With a spectral width of 12019 Hz and 131072 data points this corresponds to a halfwidth at half height of approx. 0.48 Hz. The corresponding calculation is: (12019 Hz / 131071 dp) * 5.25 dp.
\item \code{x_0}: Center of the Lorentz curves in scaled data points.
}
}
\description{
Deconvolutes NMR spectra by modeling each detected signal within a spectra as Lorentz Curve.
}
\details{
First, an automated curvature based signal selection is performed. Each signal is represented by 3 data points to allow the determination of initial Lorentz curves. These Lorentz curves are then iteratively adjusted to optimally approximate the measured spectrum.
}
\examples{
# Define the paths to the example datasets we want to deconvolute:
# `sim_dir`: directory containing 16 simulated spectra
# `sim_01`: path to the first spectrum in the `sim` directory
# `sim_01_spec`: the first spectrum in the `sim` directory as a dataframe
sim_dir <- system.file("example_datasets/bruker/sim", package = "metabodecon")
sim_1_dir <- file.path(sim_dir, "sim_01")
sim_2_dir <- file.path(sim_dir, "sim_02")
sim_1_spec <- read_spectrum(sim_1_dir)
sim_2_spec <- read_spectrum(sim_2_dir)
sim_12_specs <- list(sim_1_spec, sim_2_spec)

# Define a little wrapper function so we don't have to provide all parameters
# every time we want to start the deconvolution procedure:
glc2 <- function(data_path) {
     generate_lorentz_curves(
         data_path = data_path,
         ask = FALSE,
         sfr = c(3.42, 3.58),
         ws = 0,
         smopts = c(1, 5),
         delta = 0.1,
         nworkers = 2,
         verbose = FALSE
     )
}

# Deconvolute each input:
decon_sim_1_dir <- glc2(sim_1_dir)
decon_sim_1_spec <- glc2(sim_1_spec)
decon_sim_12_specs <- glc2(sim_12_specs)
decon_sim_dir <- glc2(sim)

# Make sure the results for the first spectrum are the same:
compare <- function(decon1, decon2) {
     ignore <- which(names(decon1) \%in\% c("number_of_files", "filename"))
     equal <- all.equal(decon1[-ignore], decon2[-ignore])
     stopifnot(isTRUE(equal))
}
compare(decon_sim_1_dir, decon_sim_1_spec)
compare(decon_sim_1_dir, decon_sim_12_specs[[1]])
compare(decon_sim_1_dir, decon_sim_dir[[1]])

# Below example uses data from a real NMR experiment, instead of (small)
# simulated datasets and therefor requires multiple seconds to run. Because
# `ask` is TRUE in this example (the default value), the user will be asked
# for input during the deconvolution. To avoid this, set `ask = FALSE`.
if (interactive()) {
     example_datasets <- download_example_datasets()
     urine_1 <- file.path(example_datasets, "bruker/urine/urine_1")
     generate_lorentz_curves(urine_1)
}
}
