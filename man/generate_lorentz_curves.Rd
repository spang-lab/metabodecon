% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/30_generate_lorentz_curves.R
\name{generate_lorentz_curves}
\alias{generate_lorentz_curves}
\title{Generate Lorentz Curves from NMR Spectra}
\usage{
generate_lorentz_curves(
  data_path = file.path(download_example_datasets(), "bruker/urine"),
  file_format = "bruker",
  make_rds = FALSE,
  expno = 10,
  procno = 10,
  nfit = 10,
  wshw = 0.1527692,
  sfr = c(11.44494, -1.8828),
  smopts = c(2, 5),
  delta = 6.4,
  sf = c(1000, 1e+06),
  ask = TRUE,
  debug = FALSE,
  ncores = "auto"
)
}
\arguments{
\item{data_path}{Either the path to an existing directory containing measured NMR spectra or a dataframe with columns \code{ppm} (parts per million) and \code{si} (signal intensity) or a list of such dataframes.}

\item{file_format}{Format of the spectra files. Either \code{"bruker"} or \code{"jcampdx"}. Only relevant if \code{data_path} is a directory.}

\item{make_rds}{Store results as rds file on disk? Should be set to TRUE if many spectra are evaluated to decrease computation time.}

\item{expno}{The experiment number for the spectra files. E.g. \code{"10"}. Only relevant if \code{data_path} is a directory and \code{file_format} is \code{"bruker"}.}

\item{procno}{The processing number for the spectra. E.g. \code{"10"}. Only relevant if \code{data_path} is a directory and \code{file_format} is \code{"bruker"}.}

\item{nfit}{Number of iterations for the approximation of the parameters for the Lorentz curves.}

\item{wshw}{Half width of the water artefact in ppm.}

\item{sfr}{Row vector with two entries consisting of the ppm positions for the left and right border of the signal free region of the spectrum.}

\item{smopts}{Vector with two entries consisting of the number of smoothing iterations and the number of data points to use for smoothing (must be uneven).}

\item{delta}{Threshold value to distinguish between signal and noise.}

\item{sf}{Vector with two entries consisting of the factor to scale the x-axis and the factor to scale the y-axis.}

\item{ask}{Whether to ask for user input during the deconvolution process. If set to FALSE, the provided default values will be used.}

\item{debug}{Whether to return additional intermediate results for debugging purposes.}

\item{ncores}{Number of cores to use for parallel processing. If set to \code{"auto"}, the number of cores will be determined automatically. If set to a number greater than 1, the number of cores will be limited to the number of spectra or 1 if the operating system is Windows.}
}
\value{
A list of deconvoluted spectra. Each list element contains a list with the following elements:
\itemize{
\item \code{number_of_files}: Number of deconvoluted spectra.
\item \code{filename}: Name of the analyzed spectrum.
\item \code{x_values}: Scaled datapoint numbers (SDP). Datapoints are numbered in descending order going from N to 0, where N equals the . Scaled data point numbers are obtained by dividing these numbers by the x-axis scale factor \code{sf[1]}. I.e., for a spectrum with 131072 datapoints and a scale factor of 1000, the first scale datapoint has value 131.071 and the last one has value 0.
\item \code{x_values_ppm}: The chemical shift of each datapoint in ppm (parts per million).
\item \code{y_values}: The scaled signal intensity (SSI) of each datapoint. Obtained by reading the raw intensity values from the provided \code{data_path} as integers and dividing them by the y-axis scale factor \code{sf[2]}.
\item \code{spectrum_superposition}: Scaled signal intensity obtained by calculating the sum of all estimated Lorentz curves for each data point.
\item \code{mse_normed}: Normalized mean squared error. Calulcated as $\frac{1}{n} \sum{i=1}{n} (z_i - \hat{z}_i)^2$ where $z_i$ is the normalized, smoothed signal intensity of data point i and $\hat{z}_i$ is the normalized superposition of Lorentz curves at data point i. Normalized in this context means that the vectors were scaled so the sum over all data points equals 1.
\item \code{index_peak_triplets_middle}: Datapoint numbers of peak centers.
\item \code{index_peak_triplets_left}: Datapoint numbers of left peak borders.
\item \code{index_peak_triplets_right}: Datapoint numbers of right peak borders.
\item \code{peak_triplets_middle}: Chemical shift of peak centers in ppm .
\item \code{peak_triplets_left}: Chemical shift of left peak borders in ppm .
\item \code{peak_triplets_right}: Chemical shift of right peak borders in ppm .
\item \code{integrals}: Integrals of the Lorentz curves.
\item \code{signal_free_region}: Borders of the signal free region of the spectrum in scaled datapoint numbers. Left of the first element and right of the second element no signals are expected.
\item \code{range_water_signal_ppm}: Half width of the water signal in ppm. Potential signals in this region are ignored.
\item \code{A}: Amplitude parameter of the Lorentz curves. Provided as negative number to maintain backwards compatiblity with MetaboDecon1D. The area under the Lorentz curve is calculated as $A \cdot \pi$.
\item \code{lambda}: Half width of the Lorentz curves in scaled data points. Provided as negative value to maintain backwards compatiblity with MetaboDecon1D. Example: a value of -0.00525 corresponds to 5.25 data points. With a spectral width of 12019 Hz and 131072 data points this corresponds to a halfwidth at half height of approx. 0.48 Hz. The corresponding calculation is: (12019 Hz / 131071 dp) * 5.25 dp.
\item \code{x_0}: Center of the Lorentz curves in scaled data points.
}
}
\description{
Deconvolutes NMR spetra and generates a Lorentz curve for each detected signal within a spectra.
}
\details{
First, an automated curvature based signal selection is performed. Each signal is represented by 3 data points to allow the determination of initial Lorentz curves. These Lorentz curves are then iteratively adjusted to optimally approximate the measured spectrum.
}
\examples{
\donttest{
path_xds <- download_example_datasets()
path_urine <- file.path(path_xds, "bruker/urine")
path_urine_1 <- file.path(path_urine, "urine_1")
decons <- generate_lorentz_curves(path_urine, ask = FALSE, nfit = 1)
decon_urine_1 <- generate_lorentz_curves(path_urine_1, ask = FALSE)[[1]]
}
}
